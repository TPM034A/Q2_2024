{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPM034A Machine Learning for socio-technical systems \n",
    "## `Assignment 02: Embeddings and Explainable Artificial Intelligence (xAI)`\n",
    "\n",
    "**Delft University of Technology**<br>\n",
    "**Q2 2024**<br>\n",
    "**Instructor:** Sander van Cranenburgh & Giacomo Marangoni <br>\n",
    "**TAs:**  Francisco Garrido Valenzuela & Lucas Spierenburg <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Instructions`\n",
    "\n",
    "**Assignments aim to:**<br>\n",
    "* Examine your understanding of the key concepts and techniques.\n",
    "* Examine your the applied ML skills.\n",
    "\n",
    "**Assignments:**<br>\n",
    "* Are graded and must be submitted (see the submission instruction below). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Google Colab workspace set-up`\n",
    "\n",
    "Uncomment the following cells code lines if you are running this notebook on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/TPM034A/Q2_2024\n",
    "#!pip install -r Q2_2024/requirements_colab.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Application: Visual urban environment as component for bike speed and safety` <br>\n",
    "\n",
    "### **Introduction**\n",
    "\n",
    "In the previous assignment, you worked with machine learning models to predict cycling speeds using tabular data, such as road infrastructure. While this approach allowed us to explore cycling speeds and make some predictions, it represents only one way to understand and predict cycling dynamics. This assignment builds on your previous work by introducing new datasets and tools to approach the same problem from two different perspectives: exploring the visual components of the urban space for predicting cycling speed, and examining the explainability of cycling accidents.\n",
    "\n",
    "In the first part of this assignment, you will focus on using images of urban spaces to predict cycling speeds. By generating image embeddings that represent visual features, such as road quality and surrounding infrastructure, you will train machine learning models to incorporate this new dimension of data. This will provide insights into how visual elements contribute to cycling speeds and how they can complement tabular data.\n",
    "\n",
    "The second part of the assignment shifts the focus to safety and explainability. By integrating accident data with our tabular information, you will explore and explain bike accidents. Using explainable AI techniques, you will interpret model predictions to uncover patterns and risk factors, offering actionable insights for improving urban cycling infrastructure and safety.\n",
    "\n",
    "#### **Data**\n",
    "For this assignment you have access to different datasets. All of them will be available in the data folder after the execution of cell below this instructions. The data folder contains four sub-folder: `image_tabular`, `bike_speeds`, `traffic_accidents` and `images`. The following list describes the datasets within the folders.\n",
    "\n",
    "1. `data/image_tabular/image_metadata.csv`: A csv file with the image metadata (e.g., year, month or location) of Rotterdam images. The column `in_folder` indicates is the img file is present in the `data/images`.\n",
    "2. `data/image_tabular/image_embeddings.csv`: A tabular csv file with image embeddings from Rotterdam.\n",
    "3. `data/bike_speeds/bike_speeds.gpkg`: A geo dataset of linestrings (streets) for the Netherlands with bike speed data.\n",
    "4. `data/traffic_accidents/accident_events.geojson`: A geographical dataset with information and characteristics of accidents for Rotterdam.\n",
    "5. `data/traffic_accidents/accident_parties.csv`: A tabular csv with the information of the parties involved in the accidents.\n",
    "6. `data/images`: A folder with image files from Rotterdam. Images in this folder are indicated by the column `in_folder` in `data/image_tabular/image_metadata.csv` with a 1.\n",
    "\n",
    "As indicated, run the code in the cell below to prepare the dataset. The cell will download the datasets and place them in the data folder automatically for this assigment. It may take up to two minutes to download the data.\n",
    "\n",
    "Remember to transform all geographical datasets (if it is needed) to the Dutch projection: **28992**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTANT: You have to be on the TUDelft network (eduroam) or under eduVPN to run this script # comment after running\n",
    "## You can comment these lines after downloading the data.\n",
    "from assets import data_downloader as dld\n",
    "dld.download_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tasks and grading**\n",
    "\n",
    "Your assignment is divided into two sections: Part I: Image Embeddings, and Part II: Explainable AI. The specific tasks and grading points for each section are outlined below.\n",
    "\n",
    "1. **Part I: Image embeddings** [5 pts]<br>\n",
    "    1. **Data preparation and exploration** [1.0 pnt]<br>\n",
    "        - Loading the datasets. \n",
    "        - Preparing the image dataset. \n",
    "        - Combining bike speed data with the images. \n",
    "        - Exploring the street view images \n",
    "    1. **Model training** [2.5 pnt]<br>\n",
    "        - Data preparation for training (random and spatial) \n",
    "        - Training a Linear Regression (LR) \n",
    "        - Training a Random Forest (RF) \n",
    "        - Training a Multi-Layer Perceptron (MLP) \n",
    "    1. **Model selection and application** [1.5 pnt]<br>\n",
    "        - Discussion on data split\n",
    "        - Model selection and application\n",
    "1. **Part II: Explainable AI** [5 pts]<br>\n",
    "    1. **Data preparation and exploration** [1.0 pnt]<br>\n",
    "        - Loading the datasets.\n",
    "        - Combining bike speed data with accidents. \n",
    "    1. **Exploring explainability using accidents aggregated by streets** [1.5 pnt]\n",
    "        - Data preparation\n",
    "        - Model preparation\n",
    "        - Explainability\n",
    "    1. **Exploring explainability using accidents instances** [1.5 pnt]\n",
    "        - Data preparation\n",
    "        - Model preparation\n",
    "        - Explainability\n",
    "    1. **Reflection** [1.0 pnt]\n",
    "\n",
    "    ### **Submission**\n",
    "- The deadline for this assignment is **Monday, December 12th, 2024** \n",
    "- Use **Python 3.11**\n",
    "- You have to submit your work in ipynb **(fully executed)** into Brightspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Plotting and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from PIL import Image\n",
    "import contextily as ctx\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Explainaibility AI\n",
    "import shap\n",
    "from lime import lime_tabular\n",
    "\n",
    "# Others\n",
    "from shapely.geometry import Point\n",
    "from pathlib import Path\n",
    "\n",
    "# pd settings\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Image embeddings\n",
    "### **1. Data preparation and exploration**\n",
    "#### **1.1. Loading datasets.** Load the datasets from the folders: image_tabular and bike_speeds. Explore them with `df.head()` for you to familiarize with the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.2. Preparing the image dataset.** Combine the `img_metadata` dataframe with the `img_embeddings` for consolidating it in one unique dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.3. Combining bike speed data with the image embeddings** \n",
    "- (a) Link the bike speed data (represented as linestrings for streets) with the images (represented as point locations). You can apply any suitable spatial aggregation method to join the data. *HINT*: Use 'u-v' as the unique identifier for each street to keep each street only one time, and consider using the buffer function in GeoPandas for this task.\n",
    "- (b) As one street object may contain several images, group by the rows by the street and average the embedding features. As a result you should have each street once. Remove the columns that doesn't make sense to have and include the linestring geometry.\n",
    "- (c) Visualize the result in a map. Plot the all images (points) and resulting streets with image data. For better visualization just show Y within 436000-438000 and X within 92000-96000 (using EPSG:28992)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.4. Exploring the street view images.**\n",
    "- (a) Explore the distribution of the speed (`speed`) in the dataset built in 1.3. Remove outliers and plot the final distribution: The histogram and a map. In the map, color the streets based on the speed.\n",
    "- (b) Sample ten street view images (present in the folder, i.e., in_folder == 1) from streets with a speed between 20 and 50 km/h.\n",
    "- (c) Repeat (b) sampling images from streets with a speed between 0> and 10 km/h.\n",
    "- (d) Did you see differences in the urban scenery comparing the images from (b) and (c)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Model training**. Train different machine learning models for predicting the bike speed based on the embedding characteristics. \n",
    "\n",
    "#### **2.1. Dataset for training**. Prepare the dataset for the modelling. \n",
    "- (a) Keep only the relevant columns for the training phase: embedding columns and bike speed.\n",
    "- (b) Split the dataset train/test using two different approaches:\n",
    "    - (b.1) Random-based: Split 80%/20% randomly.\n",
    "    - (b.2) Location-based: Split 80%/20% geographically. Create a buffer around a coordinate to select 20% of the data points as test set (taking all datapoints inside the buffer).\n",
    "- (c) Plot in a map both approaches. Using blue for coloring the streets in the training set and red for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.2. Training a Linear Regression (LR)** Train a LR for predicting the bike speed using both splits separately. Report the R2 and the MSE for train and test in both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.3. Training a Random Forest (RF)**. Train a RF for predicting the bike speed using both splits separately. Report the R2 and the MSE for train and test in both cases. Hyperameter tunning is NOT needed in this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.4. Training a Multi-Layer Perceptron (MLP)**. Train a MLP for predicting the bike speed using both splits separately. Report the R2 and the MSE for train and test in both cases. Hyperameter tunning is NOT needed in this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Model selection and application**\n",
    "#### **3.1. Reflexion data splits**. Reflect on the model indicators\n",
    "- (a) Did you see difference between the splits? If so, what could cause those differences?\n",
    "- (b) Which of these two splits do you think it is more robust? why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.2. Model selection and application**. \n",
    "- (a) Choose a model for its application and justify the choice.\n",
    "- (b) Apply the selected model and plot the predicted values and the errors in two different maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Explainable AI\n",
    "### **1. Data preparation and exploration**\n",
    "#### **1.1. Loading datasets.** Load the datasets from the folder traffic_accidents. Explore them with `df.head()` for you to familiarize with the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.2. Combining bike speed data with accidents**\n",
    "- (a) Filter the accidents events to keep only the ones where a party `Fiets`, `Bromfiets`, and `Snorfiets` is involved.\n",
    "- (b) Generate two different dataset for analyzing accidents:\n",
    "    - Accident-based dataset. Each row corresponds to a unique accident, and you have to associated the characteristics of the segement where it happened.\n",
    "    HINT for b: Create a buffer of 5m around the streets for doing the spatial merge between streets and accidents.\n",
    "    \n",
    "    - Street-based dataset. Each row corresponds to a unique street segment, and you have to aggregate accident data of the ones happening within 5 meters around the street segement. For each street, you should create the following data columns:\n",
    "        - Create a column (named `n_severe`) with the total number of severe accidents (`Injury` and `Fatal` in AP3).\n",
    "        - Create a column (named `n_minor`) with the total number of minor accidents (`Only material damage` in AP3).\n",
    "        - Create a column (named `n_parties`) with the average number of parties involved in the accidents of that segment (using `N_PARTIES`).\n",
    "        - Create a columns with the max speed limit (using `MAX_SPEED`)\n",
    "        - Create a column (named `rain_prop`) with the percentage of accidents in the segement ocurring on rain/snow (`Rain`, `Fog` and `Snow/Hail` in WHEATER_1)\n",
    "        - Create a column (named `dark_prop`) with the percentage of accidents in the segement ocurring on low-light condition. (`Darkness` in LIGHT_CONDITION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Exploring explainability using accidents aggregated by streets**\n",
    "#### **2.1. Data preparation**\n",
    "\n",
    "You will be using the `street_accidents` datasets to explore the relationship between accidents and characteristics of the streets they occured.\n",
    "Key variables are:\n",
    "\n",
    "- `n_severe`: Total number of severe accidents (fatal or injured);\n",
    "- `n_minor`: Total number of minor accidents (only material damage).\n",
    "\n",
    "(a) Add a column `n_any` summing all accidents happened in that street, whether minor or severe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Then, filter the datasets only to streets with:\n",
    "- at least one accident;\n",
    "- `speed` greater than 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Create a column `highway2`, mapping the values of `highway` according to this table:\n",
    "| highway     | highway2                 |\n",
    "|------------------|-----------------------|\n",
    "| primary          | major_road            |\n",
    "| secondary        | major_road            |\n",
    "| tertiary         | major_road            |\n",
    "| primary_link     | major_road            |\n",
    "| secondary_link   | major_road            |\n",
    "| tertiary_link    | major_road            |\n",
    "| residential      | minor_road            |\n",
    "| unclassified     | minor_road            |\n",
    "| living_street    | minor_road            |\n",
    "| service          | minor_road            |\n",
    "| services         | minor_road            |\n",
    "| footway          | pedestrian_cycleway   |\n",
    "| pedestrian       | pedestrian_cycleway   |\n",
    "| cycleway         | pedestrian_cycleway   |\n",
    "| path             | pedestrian_cycleway   |\n",
    "| busway           | public_transit        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Then create 3 dummy columns (i.e. one for each `highway2` value except `public_transit`), true or false depending on the value of `highway2`:\n",
    "- highway2_major_road\n",
    "- highway2_minor_road\n",
    "- highway2_pedestrian_cycleway\n",
    "\n",
    "(e) Finally, remove all non-numeric columns, make sure the remaining ones are numeric, and drop any rows with NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.2. Model preparation**\n",
    "\n",
    "(a) Set up a classification model called `model4xai` using a RandomForest to predict whether an accident on a street segment is severe (i.e., involves death or injury).\n",
    "\n",
    "Use as features:\n",
    "- `oneway` (0 = false, 1 = true)\n",
    "- `length`\n",
    "- `speed` (i.e. the average speed)\n",
    "- `n_observations` (i.e. the traffic)\n",
    "- the `highway2` dummies you created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.3. Explainability**\n",
    "\n",
    "(a) How does `speed` affect the likelihood of severe accidents? Use a partial dependence plot and explain the resulting relationship on the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Use a SHAP `KernelExplainer` to compute the SHAP values for the test set.\n",
    "As background parameter, use `shap.kmeans` to summarize the train dataset via 10 centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Plot and explain a summary plot of the SHAP values. What insights can you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Take the first row of the test dataset: is it a \"safe\" street according to our model? Explain how each feature contributed to the final prediction.\n",
    "Hint: use a waterfall plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Compute the explanation you would get with LIME: how does it compare with SHAP? How can that be explained?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Exploring explainability using accidents instances**\n",
    "\n",
    "Use the `accident_street` dataset, containing accidents as rows.\n",
    "\n",
    "#### **3.1. Data preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Simplify the columns following these remapping tables (1st column: original values, 2nd column: mapped values):\n",
    "\n",
    "- Road type (as above, see highway2)\n",
    "\n",
    "- Weather conditions\n",
    "\n",
    "| WEATHER_1        | weather2     |\n",
    "|-----------------|------------------|\n",
    "| Dry           | clear            |\n",
    "| Rain           | precipitation    |\n",
    "| Snow/Hail    | precipitation    |\n",
    "| Fog            | adverse          |\n",
    "| Strong wind gusts| adverse          |\n",
    "| Unknown       | other            |\n",
    "\n",
    "- Surface Types Mapping\n",
    "\n",
    "| ROAD_SURFACE_CONDITION                             | surface2 |\n",
    "|--------------------------------------|--------------|\n",
    "| Overig asfalt                        | asphalt      |\n",
    "| ASFALT                               | asphalt      |\n",
    "| ASVALT                               | asphalt      |\n",
    "| ASFALT TEGELS                        | asphalt      |\n",
    "| ASFALT FIETSPAD EN STOEPTEGELS       | asphalt      |\n",
    "| ZOAB                                 | asphalt      |\n",
    "| BITUMEN EN KLINKERS                  | asphalt      |\n",
    "| KLINKERS OVERGAANDE IN BITUMEN       | asphalt      |\n",
    "| BITUMEN FIETSPAD KLINKERWEG          | asphalt      |\n",
    "| STOEPTEGELSFIETSPAD BITUMEN          | asphalt      |\n",
    "| DEELS KLINKERS DEELS BITUMEN         | asphalt      |\n",
    "| BITUMEN                              | asphalt      |\n",
    "| KLINKERS EN BITUMEN                  | asphalt      |\n",
    "| Klinkers                             | pavement     |\n",
    "| Beton                                | pavement     |\n",
    "| KEIEN                                | pavement     |\n",
    "| STOEPTEGELS                          | pavement     |\n",
    "| TEGELS                               | pavement     |\n",
    "| 30 30 BETONTEGELS                    | pavement     |\n",
    "| STOEPTEGELS 30X30                    | pavement     |\n",
    "| TROTTOIR TEGELS                      | pavement     |\n",
    "| STENEN                               | pavement     |\n",
    "| TEGELS VOETPAD                       | pavement     |\n",
    "| STRAATTEGELS                         | pavement     |\n",
    "| KUNSTSTOF RIJPLATEN                  | pavement     |\n",
    "| BETONNEN RIJPLATEN                   | pavement     |\n",
    "| GRAS                                 | pavement     |\n",
    "| TRAMRAILS MET DAARIN EEN GAT I       | other        |\n",
    "| TRAMRAILS                            | other        |\n",
    "| LOS GRAVEL                           | other        |\n",
    "| IJZEREN ROOSTER                      | other        |\n",
    "| GLAD WEGDEK                          | other        |\n",
    "| KUNSTSTOF RIJPLATEN                  | other        |\n",
    "\n",
    "- Road Light Conditions Mapping\n",
    "\n",
    "| ROAD_LIGHT_CONDITION           | light2 |\n",
    "|--------------------|--------------|\n",
    "| Lit           | lit          |\n",
    "| Not Lit      | not_lit      |\n",
    "| Not present      | no_lighting  |\n",
    "\n",
    "\n",
    "(b) Then create 0/1 dummies columns for each of `highway2`, `weather2`, `surface2`, `light2`. Create a `severe` column which is 1 if `AP3` is `Injury` or `Fatal`, 0 otherwise. Drop all non-numeric columns, rows with NAs and rows with `speed` = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.2. Model preparation**\n",
    "\n",
    "(a) Set up a classification model called `model4xai2` using a RandomForest to predict whether an accident is severe (i.e., involves death or injury).\n",
    "Use as features:\n",
    "- `oneway` (0 = false, 1 = true)\n",
    "- `speed` (i.e. the average speed)\n",
    "- `n_observations` (i.e. proxi of the traffic)\n",
    "- the `highway2` dummies created above\n",
    "- the `weather2` dummies created above\n",
    "- the `surface2` dummies created above\n",
    "- the `light2` dummies created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.3. Explainability**\n",
    "\n",
    "(a) Use a SHAP `KernelExplainer` to compute the SHAP values for the test set.\n",
    "As background parameter, use `shap.kmeans` to summarize the train dataset via 10 centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) What are the 3 most important features? Use a summary BAR plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Plot a scatter plot of speed (x-axis) vs its SHAP value (y-axis). What is the difference with the partial dependence plot?\n",
    "\n",
    "Hint: use shap.plots.scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Reflextion**\n",
    "- (a) How do the two analyses with the two datasets above differ? What are instead the similiarities?\n",
    "- (b) What are the benefits of a XAI-informed model for predicting severe accidents? What could be the risks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpm034a_mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
